# 'serial_data_cleaning.py'

"""
serial_data_cleaning.py
ë°ì´í„° ì •ì œë¥¼ ìœ„í•œ í•¨ìˆ˜ ëª¨ìŒ

Author: jaehyuntak
Description: data_cleaning.ipynbë¥¼ í•¨ìˆ˜í™”í•œ ëª¨ë“ˆ
"""

# ============================================================================
# 1. ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬
# ============================================================================
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# 3. ê²½ë¡œ ì„¤ì • ë° ì‚¬ìš©ì ì •ì˜ ëª¨ë“ˆ
# ============================================================================
import sys
import os
sys.path.append('/Users/jaehyuntak/Desktop/pjt-data-analysis')

# í•œê¸€ í°íŠ¸ ì„¤ì •
from da_utils.font import setup_korean_font

# ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ëª¨ë“ˆ
from da_utils import data_profile, outliers, patterns

# ============================================================================
# 4. ëª¨ë“ˆ ì´ˆê¸°í™”
# ============================================================================
# í•œê¸€ í°íŠ¸ ì„¤ì • (ëª¨ë“ˆ import ì‹œ ìë™ ì‹¤í–‰)
setup_korean_font()

print("âœ… serial_data_cleaning ëª¨ë“ˆì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")
print("ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í•¨ìˆ˜ ëª©ë¡:")
print("   - load_data()")
print("   - analyze_missing_values()")
print("   - replace_dash_with_nan()")
print("   - process_date_columns()")
print("   - classify_transaction_status()")
print("   - (ì¶”ê°€ ì˜ˆì •...)")


# ============================================================================
# 5. ë°ì´í„° ë¡œë”© í•¨ìˆ˜
# ============================================================================

def load_data(file_path, encoding='utf-8', show_info=True):
    """
    CSV íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì •ë³´ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    file_path : str
        CSV íŒŒì¼ ê²½ë¡œ
    encoding : str, default 'utf-8'
        íŒŒì¼ ì¸ì½”ë”© ë°©ì‹
    show_info : bool, default True
        ê¸°ë³¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    pandas.DataFrame
        ë¡œë“œëœ ë°ì´í„°í”„ë ˆì„
        
    Example:
    --------
    >>> file_path = '/path/to/data.csv'
    >>> df = load_data(file_path)
    """
    try:
        # CSV íŒŒì¼ ë¡œë“œ
        df = pd.read_csv(file_path, encoding=encoding)
        
        if show_info:
            print("=" * 50)
            print("ğŸ” ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            print("=" * 50)
            print(f"ğŸ“ íŒŒì¼ ê²½ë¡œ: {file_path}")
            print(f"ğŸ“Š ë°ì´í„° í¬ê¸°: {df.shape[0]:,}í–‰ Ã— {df.shape[1]}ì—´")
            print(f"ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB")
            
            print("\n" + "=" * 50)
            print("ğŸ“‹ ë°ì´í„° íƒ€ì… ì •ë³´")
            print("=" * 50)
            print(df.dtypes)
            
            print("\n" + "=" * 50)
            print("ğŸ”¢ ê° ì»¬ëŸ¼ë³„ ê³ ìœ ê°’ ê°œìˆ˜")
            print("=" * 50)
            for col in df.columns:
                unique_count = df[col].nunique()
                print(f"   {col}: {unique_count:,}ê°œ")
            
            print("\n" + "=" * 50)
            print("ğŸ“ˆ ìˆ«ìí˜• ì»¬ëŸ¼ ê¸°ë³¸ í†µê³„")
            print("=" * 50)
            numeric_stats = df.describe()
            print(numeric_stats)
            
            print("\n" + "=" * 50)
            print("ğŸ‘€ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)")
            print("=" * 50)
            print(df.head())
            
        return df
        
    except FileNotFoundError:
        print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        return None
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None
    


    

# ============================================================================
# 6. ê²°ì¸¡ì¹˜ ë¶„ì„ í•¨ìˆ˜
# ============================================================================

def analyze_missing_values(df, show_details=True):
    """
    ëª…ì‹œì  ê²°ì¸¡ì¹˜(NaN)ì™€ ì•”ë¬µì  ê²°ì¸¡ì¹˜('-' ë¬¸ì)ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        ë¶„ì„í•  ë°ì´í„°í”„ë ˆì„
    show_details : bool, default True
        ìƒì„¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    dict
        ê²°ì¸¡ì¹˜ ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        - 'null_summary': ëª…ì‹œì  ê²°ì¸¡ì¹˜ ìš”ì•½
        - 'dash_summary': ì•”ë¬µì  ê²°ì¸¡ì¹˜ ìš”ì•½
        
    Example:
    --------
    >>> missing_info = analyze_missing_values(df)
    """
    result = {}
    
    if show_details:
        print("=" * 50)
        print("ğŸ” ê²°ì¸¡ì¹˜ ë¶„ì„")
        print("=" * 50)
    
    # 1. ëª…ì‹œì  ê²°ì¸¡ì¹˜(NaN) ë¶„ì„
    null_counts = df.isnull().sum()
    null_percentages = (df.isnull().sum() / len(df)) * 100
    null_summary = pd.DataFrame({
        'ê²°ì¸¡ì¹˜ ê°œìˆ˜': null_counts,
        'ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)': null_percentages.round(2)
    })
    null_summary = null_summary[null_summary['ê²°ì¸¡ì¹˜ ê°œìˆ˜'] > 0].sort_values('ê²°ì¸¡ì¹˜ ë¹„ìœ¨(%)', ascending=False)
    
    result['null_summary'] = null_summary
    
    if show_details:
        print("\nğŸ“Š ëª…ì‹œì  ê²°ì¸¡ì¹˜(NaN) ë¶„ì„")
        print("-" * 30)
        if len(null_summary) > 0:
            print(null_summary)
        else:
            print("âœ… ëª…ì‹œì  ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # 2. ì•”ë¬µì  ê²°ì¸¡ì¹˜('-' ë¬¸ì) ë¶„ì„
    dash_counts = {}
    for col in df.columns:
        if df[col].dtype == 'object':  # ë¬¸ìì—´ ì»¬ëŸ¼ë§Œ í™•ì¸
            dash_count = (df[col] == '-').sum()
            if dash_count > 0:
                dash_counts[col] = {
                    'ê°œìˆ˜': dash_count,
                    'ë¹„ìœ¨(%)': round((dash_count / len(df)) * 100, 2)
                }
    
    if dash_counts:
        dash_summary = pd.DataFrame(dash_counts).T
        dash_summary = dash_summary.sort_values('ë¹„ìœ¨(%)', ascending=False)
    else:
        dash_summary = pd.DataFrame()  # ë¹ˆ ë°ì´í„°í”„ë ˆì„
        
    result['dash_summary'] = dash_summary
    
    if show_details:
        print("\nğŸ“Š ì•”ë¬µì  ê²°ì¸¡ì¹˜('-' ë¬¸ì) ë¶„ì„")
        print("-" * 30)
        if not dash_summary.empty:
            print(dash_summary)
        else:
            print("âœ… '-' ë¬¸ìë¡œ í‘œì‹œëœ ê²°ì¸¡ì¹˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # 3. ì „ì²´ ìš”ì•½
    total_nulls = null_summary['ê²°ì¸¡ì¹˜ ê°œìˆ˜'].sum() if not null_summary.empty else 0
    total_dashes = sum([info['ê°œìˆ˜'] for info in dash_counts.values()]) if dash_counts else 0
    
    if show_details:
        print(f"\nğŸ“‹ ê²°ì¸¡ì¹˜ ìš”ì•½")
        print("-" * 30)
        print(f"   ì „ì²´ ë°ì´í„°: {len(df):,}ê±´")
        print(f"   ëª…ì‹œì  ê²°ì¸¡ì¹˜(NaN): {total_nulls:,}ê°œ")
        print(f"   ì•”ë¬µì  ê²°ì¸¡ì¹˜('-'): {total_dashes:,}ê°œ")
        print(f"   ì´ ê²°ì¸¡ì¹˜: {total_nulls + total_dashes:,}ê°œ")
    
    result['total_nulls'] = total_nulls
    result['total_dashes'] = total_dashes
    result['total_missing'] = total_nulls + total_dashes
    
    return result



# ============================================================================
# 7. '-' ë¬¸ìë¥¼ NaNìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
# ============================================================================

def replace_dash_with_nan(df, columns=None, show_details=True):
    """
    ì§€ì •ëœ ì»¬ëŸ¼ë“¤ì˜ '-' ë¬¸ìë¥¼ NaNìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
    columns : list or None, default None
        ì²˜ë¦¬í•  ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸. Noneì´ë©´ ê¸°ë³¸ ì»¬ëŸ¼ë“¤ ì‚¬ìš©
    show_details : bool, default True
        ë³€í™˜ ê³¼ì • ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    pandas.DataFrame
        '-' â†’ NaN ë³€í™˜ëœ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬ë³¸
    """
    # ê¸°ë³¸ ì»¬ëŸ¼ ì„¤ì • (ì›ë³¸ ipynb íŒŒì¼ ê¸°ì¤€)
    if columns is None:
        columns = ['í•´ì œì‚¬ìœ ë°œìƒì¼', 'ë§¤ìˆ˜ì', 'ë§¤ë„ì', 'ë™', 'ë“±ê¸°ì¼ì', 'ì¤‘ê°œì‚¬ì†Œì¬ì§€']
    
    df_result = df.copy()
    
    if show_details:
        print("=" * 50)
        print("ğŸ”§ '-' ë¬¸ìë¥¼ NaNìœ¼ë¡œ ë³€í™˜")
        print("=" * 50)
    
    for col in columns:
        if col in df_result.columns:
            before_count = (df_result[col] == '-').sum()
            df_result[col] = df_result[col].replace('-', np.nan)
            after_count = df_result[col].isna().sum()
            
            if show_details:
                print(f"   {col}: {before_count:,}ê°œ '-' â†’ {after_count:,}ê°œ NaN")
        else:
            if show_details:
                print(f"   âš ï¸ ì»¬ëŸ¼ '{col}'ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
    
    return df_result



# ============================================================================
# 8. ë‚ ì§œ ì²˜ë¦¬ í•¨ìˆ˜ë“¤
# ============================================================================

def process_date_columns(df, show_details=True):
    """
    ë‚ ì§œ ê´€ë ¨ ì»¬ëŸ¼ë“¤ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    1. ì¤‘ë³µ ë‚ ì§œ ì»¬ëŸ¼ ì œê±° (ê³„ì•½ì¼ì ì‚­ì œ)
    2. ê³„ì•½ë‚ ì§œ ìƒì„± (ê³„ì•½ë…„ì›” + ê³„ì•½ì¼)
    3. ë“±ê¸°ì¼ì datetime ë³€í™˜
    
    Parameters:
    -----------
    df : pandas.DataFrame
        ì²˜ë¦¬í•  ë°ì´í„°í”„ë ˆì„
    show_details : bool, default True
        ì²˜ë¦¬ ê³¼ì • ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    pandas.DataFrame
        ë‚ ì§œ ì²˜ë¦¬ëœ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬ë³¸
    """
    df_result = df.copy()
    
    if show_details:
        print("=" * 50)
        print("ğŸ“… ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬")
        print("=" * 50)
    
    # 1. ì¤‘ë³µ ë‚ ì§œ ì»¬ëŸ¼ ì œê±° (ê³„ì•½ì¼ìê°€ ìˆìœ¼ë©´ ì‚­ì œ)
    if 'ê³„ì•½ì¼ì' in df_result.columns:
        df_result = df_result.drop(columns=['ê³„ì•½ì¼ì'])
        if show_details:
            print("   âœ… ì¤‘ë³µ ì»¬ëŸ¼ 'ê³„ì•½ì¼ì' ì‚­ì œ")
    
    # 2. ê³„ì•½ë‚ ì§œ ìƒì„± (ê³„ì•½ë…„ì›” + ê³„ì•½ì¼ â†’ ê³„ì•½ë‚ ì§œ)
    if 'ê³„ì•½ë…„ì›”' in df_result.columns and 'ê³„ì•½ì¼' in df_result.columns:
        df_result['ê³„ì•½ë‚ ì§œ'] = pd.to_datetime(
            df_result['ê³„ì•½ë…„ì›”'].astype(str) + df_result['ê³„ì•½ì¼'].astype(str).str.zfill(2),
            format='%Y%m%d'
        )
        if show_details:
            print("   âœ… ê³„ì•½ë‚ ì§œ ìƒì„± (ê³„ì•½ë…„ì›” + ê³„ì•½ì¼)")
            print(f"      ê¸°ê°„: {df_result['ê³„ì•½ë‚ ì§œ'].min()} ~ {df_result['ê³„ì•½ë‚ ì§œ'].max()}")
    
    # 3. ë“±ê¸°ì¼ì datetime ë³€í™˜
    if 'ë“±ê¸°ì¼ì' in df_result.columns:
        before_count = df_result['ë“±ê¸°ì¼ì'].notna().sum()
        df_result['ë“±ê¸°ì¼ì'] = pd.to_datetime(
            df_result['ë“±ê¸°ì¼ì'], 
            format='%y.%m.%d', 
            errors='coerce'
        )
        after_count = df_result['ë“±ê¸°ì¼ì'].notna().sum()
        
        if show_details:
            print(f"   âœ… ë“±ê¸°ì¼ì datetime ë³€í™˜")
            print(f"      ë³€í™˜ ì„±ê³µ: {after_count:,}ê±´")
            print(f"      ë³€í™˜ ì‹¤íŒ¨ ë˜ëŠ” ì›ë˜ NaN: {len(df_result) - after_count:,}ê±´")
    
    if show_details:
        print(f"\n   ğŸ“‹ ì²˜ë¦¬ í›„ ì»¬ëŸ¼ ìˆ˜: {len(df_result.columns)}ê°œ")
        
    return df_result



# ============================================================================
# 9. ê±°ë˜ìƒíƒœ ë¶„ë¥˜ í•¨ìˆ˜
# ============================================================================

def classify_transaction_status(df, show_details=True):
    """
    ê±°ë˜ ìƒíƒœë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    - ì •ìƒì™„ë£Œ: í•´ì œì‚¬ìœ  ì—†ìŒ & ë“±ê¸°ì¼ì ìˆìŒ
    - í•´ì œ: í•´ì œì‚¬ìœ  ìˆìŒ
    - ì§„í–‰ì¤‘: í•´ì œì‚¬ìœ  ì—†ìŒ & ë“±ê¸°ì¼ì ì—†ìŒ
    
    Parameters:
    -----------
    df : pandas.DataFrame
        ë¶„ë¥˜í•  ë°ì´í„°í”„ë ˆì„
    show_details : bool, default True
        ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    pandas.DataFrame
        ê±°ë˜ìƒíƒœ ì»¬ëŸ¼ì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„ ë³µì‚¬ë³¸
    """
    df_result = df.copy()
    
    if show_details:
        print("=" * 50)
        print("ğŸ·ï¸ ê±°ë˜ìƒíƒœ ë¶„ë¥˜")
        print("=" * 50)
    
    # ê±°ë˜ìƒíƒœ ì´ˆê¸°í™”
    df_result['ê±°ë˜ìƒíƒœ'] = 'ê¸°íƒ€'
    
    # 1. ì •ìƒì™„ë£Œ: í•´ì œì‚¬ìœ  ì—†ìŒ & ë“±ê¸°ì¼ì ìˆìŒ
    normal_mask = (df_result['í•´ì œì‚¬ìœ ë°œìƒì¼'].isna()) & (df_result['ë“±ê¸°ì¼ì'].notna())
    df_result.loc[normal_mask, 'ê±°ë˜ìƒíƒœ'] = 'ì •ìƒì™„ë£Œ'
    
    # 2. í•´ì œ: í•´ì œì‚¬ìœ  ìˆìŒ
    cancel_mask = df_result['í•´ì œì‚¬ìœ ë°œìƒì¼'].notna()
    df_result.loc[cancel_mask, 'ê±°ë˜ìƒíƒœ'] = 'í•´ì œ'
    
    # 3. ì§„í–‰ì¤‘: í•´ì œì‚¬ìœ  ì—†ìŒ & ë“±ê¸°ì¼ì ì—†ìŒ
    ongoing_mask = (df_result['í•´ì œì‚¬ìœ ë°œìƒì¼'].isna()) & (df_result['ë“±ê¸°ì¼ì'].isna())
    df_result.loc[ongoing_mask, 'ê±°ë˜ìƒíƒœ'] = 'ì§„í–‰ì¤‘'
    
    if show_details:
        print("ğŸ“Š ê±°ë˜ìƒíƒœë³„ ë¶„í¬:")
        status_counts = df_result['ê±°ë˜ìƒíƒœ'].value_counts()
        for status, count in status_counts.items():
            percentage = count / len(df_result) * 100
            print(f"   - {status}: {count:,}ê±´ ({percentage:.1f}%)")
        
        # ê±°ë˜ìƒíƒœë³„ ê²°ì¸¡ íŒ¨í„´ ë¶„ì„
        print("\nğŸ“‹ ê±°ë˜ìƒíƒœë³„ ì£¼ìš” í•„ë“œ ê²°ì¸¡ë¥ :")
        status_missing = df_result.groupby('ê±°ë˜ìƒíƒœ')[['ë™', 'ë“±ê¸°ì¼ì', 'í•´ì œì‚¬ìœ ë°œìƒì¼', 'ë§¤ìˆ˜ì', 'ì¤‘ê°œì‚¬ì†Œì¬ì§€']].apply(
            lambda x: x.isna().sum() / len(x) * 100
        ).round(1)
        print(status_missing)
    
    return df_result



# ============================================================================
# 10. ì •ìƒê±°ë˜ í•„í„°ë§ ë° ê±°ë˜ê¸ˆì•¡ ë³€í™˜ í•¨ìˆ˜
# ============================================================================

def filter_normal_transactions(df, show_details=True):
    """
    ì •ìƒì™„ë£Œ ê±°ë˜ë§Œ í•„í„°ë§í•˜ê³  ê±°ë˜ê¸ˆì•¡ì„ ìˆ«ìí˜•ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        í•„í„°ë§í•  ë°ì´í„°í”„ë ˆì„ (ê±°ë˜ìƒíƒœ ì»¬ëŸ¼ í•„ìš”)
    show_details : bool, default True
        í•„í„°ë§ ê²°ê³¼ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    pandas.DataFrame
        ì •ìƒì™„ë£Œ ê±°ë˜ë§Œ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
    """
    if show_details:
        print("=" * 50)
        print("âœ… ì •ìƒê±°ë˜ í•„í„°ë§ ë° ë°ì´í„° ë³€í™˜")
        print("=" * 50)
    
    # ì •ìƒì™„ë£Œ ê±°ë˜ë§Œ í•„í„°ë§
    df_normal = df[df['ê±°ë˜ìƒíƒœ'] == 'ì •ìƒì™„ë£Œ'].copy()
    
    # ê±°ë˜ê¸ˆì•¡ì„ ìˆ«ìë¡œ ë³€í™˜
    df_normal['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'] = df_normal['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'].str.replace(',', '').astype(int)
    
    if show_details:
        print(f"ğŸ“Š ë°ì´í„° í•„í„°ë§ ê²°ê³¼:")
        print(f"   ì›ë³¸ ë°ì´í„°: {len(df):,}ê±´")
        print(f"   ì •ìƒì™„ë£Œ ê±°ë˜: {len(df_normal):,}ê±´ ({len(df_normal)/len(df)*100:.1f}%)")
        print(f"   ì œì™¸ëœ ê±°ë˜: {len(df) - len(df_normal):,}ê±´")
        
        print(f"\nğŸ“‹ ì •ìƒì™„ë£Œ ê±°ë˜ì˜ íŠ¹ì„±:")
        if 'ê³„ì•½ë‚ ì§œ' in df_normal.columns:
            print(f"   ê¸°ê°„: {df_normal['ê³„ì•½ë‚ ì§œ'].min().strftime('%Y-%m-%d')} ~ {df_normal['ê³„ì•½ë‚ ì§œ'].max().strftime('%Y-%m-%d')}")
        print(f"   í‰ê·  ê±°ë˜ê°€ê²©: {df_normal['ê±°ë˜ê¸ˆì•¡(ë§Œì›)'].mean():,.0f}ë§Œì›")
        print(f"   í‰ê·  ì „ìš©ë©´ì : {df_normal['ì „ìš©ë©´ì (ã¡)'].mean():.1f}ã¡")
        
        # ì§€ì—­ë³„ ë¶„í¬ (ì‹œêµ°êµ¬ì—ì„œ ì§€ì—­ ì¶”ì¶œ)
        if 'ì‹œêµ°êµ¬' in df_normal.columns:
            df_normal_temp = df_normal.copy()
            df_normal_temp['ì§€ì—­'] = df_normal_temp['ì‹œêµ°êµ¬'].str.split().str[0]  # ì²« ë²ˆì§¸ ë‹¨ì–´ë§Œ ì¶”ì¶œ
            print(f"\nğŸ“ ì§€ì—­ë³„ ì •ìƒì™„ë£Œ ê±°ë˜ ë¶„í¬:")
            region_dist = df_normal_temp['ì§€ì—­'].value_counts()
            for region, count in region_dist.items():
                print(f"   - {region}: {count:,}ê±´ ({count/len(df_normal)*100:.1f}%)")
    
    return df_normal


# ============================================================================
# 11. ë°ì´í„° ì €ì¥ í•¨ìˆ˜
# ============================================================================

def save_cleaned_data(df, output_path, filename=None, show_details=True):
    """
    ì •ì œëœ ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    df : pandas.DataFrame
        ì €ì¥í•  ë°ì´í„°í”„ë ˆì„
    output_path : str
        ì €ì¥í•  í´ë” ê²½ë¡œ
    filename : str or None, default None
        íŒŒì¼ëª…. Noneì´ë©´ ìë™ ìƒì„±
    show_details : bool, default True
        ì €ì¥ ê²°ê³¼ ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    str
        ì €ì¥ëœ íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œ
    """
    import os
    from datetime import datetime
    
    # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
    os.makedirs(output_path, exist_ok=True)
    
    # íŒŒì¼ëª… ìë™ ìƒì„±
    if filename is None:
        timestamp = datetime.now().strftime('%Y%m%d')
        filename = f'cleaned_normal_transactions_{timestamp}.csv'
    
    # ì „ì²´ ê²½ë¡œ
    full_path = os.path.join(output_path, filename)
    
    # CSV ì €ì¥
    df.to_csv(full_path, index=False, encoding='utf-8')
    
    if show_details:
        print("=" * 50)
        print("ğŸ’¾ ë°ì´í„° ì €ì¥ ì™„ë£Œ")
        print("=" * 50)
        print(f"   ğŸ“ ì €ì¥ ê²½ë¡œ: {full_path}")
        print(f"   ğŸ“Š ì €ì¥ëœ ë°ì´í„°: {len(df):,}ê±´")
        print(f"   ğŸ“‹ ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ")
        print(f"   ğŸ’½ íŒŒì¼ í¬ê¸°: {os.path.getsize(full_path) / 1024**2:.2f} MB")
    
    return full_path


# ============================================================================
# 12. ì „ì²´ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜
# ============================================================================

def clean_all_data(file_path, output_path=None, save_result=True, show_details=True):
    """
    ì „ì²´ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    file_path : str
        ì›ë³¸ CSV íŒŒì¼ ê²½ë¡œ
    output_path : str or None, default None
        ì €ì¥í•  í´ë” ê²½ë¡œ. Noneì´ë©´ ì €ì¥ ì•ˆí•¨
    save_result : bool, default True
        ê²°ê³¼ ì €ì¥ ì—¬ë¶€
    show_details : bool, default True
        ì „ì²´ ê³¼ì • ì¶œë ¥ ì—¬ë¶€
        
    Returns:
    --------
    pandas.DataFrame
        ì •ì œ ì™„ë£Œëœ ë°ì´í„°í”„ë ˆì„
    """
    if show_details:
        print("ğŸš€ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        print("=" * 70)
    
    # 1. ë°ì´í„° ë¡œë“œ
    df = load_data(file_path, show_info=show_details)
    if df is None:
        return None
    
    # 2. ê²°ì¸¡ì¹˜ ë¶„ì„
    missing_info = analyze_missing_values(df, show_details=show_details)
    
    # 3. '-' â†’ NaN ë³€í™˜
    df = replace_dash_with_nan(df, show_details=show_details)
    
    # 4. ë‚ ì§œ ì²˜ë¦¬
    df = process_date_columns(df, show_details=show_details)
    
    # 5. ê±°ë˜ìƒíƒœ ë¶„ë¥˜
    df = classify_transaction_status(df, show_details=show_details)
    
    # 6. ì •ìƒê±°ë˜ í•„í„°ë§
    df_final = filter_normal_transactions(df, show_details=show_details)
    
    # 7. ë°ì´í„° ì €ì¥
    if save_result and output_path:
        saved_path = save_cleaned_data(df_final, output_path, show_details=show_details)
    
    if show_details:
        print("\n" + "=" * 70)
        print("ğŸ‰ ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        print("=" * 70)
        print(f"ğŸ“Š ìµœì¢… ê²°ê³¼: {len(df_final):,}ê±´ì˜ ì •ìƒê±°ë˜ ë°ì´í„°")
        
    return df_final